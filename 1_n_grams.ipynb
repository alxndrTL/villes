{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement des données\n",
    "\n",
    "fichier = open('villes.txt')\n",
    "donnees = fichier.read()\n",
    "villes = donnees.replace('\\n', ',').split(',')\n",
    "\n",
    "# préparation des données\n",
    "\n",
    "# on rajoute le token . au début et en fin (fait office de signal de départ et de fin)\n",
    "for ville, i in zip(villes, range(len(villes))):\n",
    "    villes[i] = '.' + ville + '.'\n",
    "\n",
    "# création du vocabulaire\n",
    "vocabulaire = []\n",
    "\n",
    "for ville in villes:\n",
    "    for c in ville:\n",
    "        if c not in vocabulaire:\n",
    "            vocabulaire.append(c)\n",
    "\n",
    "vocabulaire = sorted(vocabulaire)\n",
    "vocabulaire[0] = '.' # 0 est \" \" et 3 est \".\" -> on échange\n",
    "vocabulaire[3] = ' '\n",
    "\n",
    "# pour convertir char <-> int\n",
    "char_to_int = {}\n",
    "int_to_char = {}\n",
    "\n",
    "for (c, i) in zip(vocabulaire, range(len(vocabulaire))):\n",
    "    char_to_int[c] = i\n",
    "    int_to_char[i] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random (0-gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aucun apprentissage : on génère des lettres du vocabulaire de manière aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"âpjfpüzvnüyâlvk'dq pqtj-'ûexgm\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(random.choice(vocabulaire) for _ in range(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est pas terrible..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7842)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on calcule facilement le coût\n",
    "# puisqu'on choisit aléatoirement les lettres, cela revient à assigner une proba de 1/len(voc) à toutes les lettres\n",
    "# la formule du cout est -log p_model(bonne lettre | contexte)\n",
    "# ici le contexte est vide, et on obtient donc -log(1/len(voca))\n",
    "\n",
    "-torch.log(torch.tensor(1/len(vocabulaire)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fois, il y a un tout petit \"apprentissage\" : on va compter la fréquence de chaque lettre parmis les 36000 noms de communes.\n",
    "\n",
    "Ensuite, on génère des lettres à partir de ces fréquences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création du dataset\n",
    "\n",
    "# matrice des données, qui sera de taille (M, 1) pour le unigram\n",
    "# on y place simplement toutes les lettres de toutes les communes\n",
    "X = []\n",
    "\n",
    "for ville in villes:\n",
    "    for char in ville:\n",
    "        X.append([char_to_int[char]])\n",
    "\n",
    "X = torch.asarray(X) # (M, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modèle uni-gram\n",
    "P = torch.zeros((len(vocabulaire))) # liste de probabilités d'apparition de chaque lettre\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    P[X[i]] += 1 # on augmente le compteur de chaque lettre rencontrée\n",
    "\n",
    "P = P / P.sum(dim=0, keepdim=True) # on transforme les nombres d'apparitions en probabilités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a-cqsu\n",
      "n\n",
      "o\n",
      "sayoemnraro\n",
      "\n",
      "ianèriaesom\n",
      "aom--ei\n",
      "l\n",
      "oitabu\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(40+5)\n",
    "\n",
    "for _ in range(10):\n",
    "    # on génère une lettre tant qu'on ne tombe pas sur \".\", qui signifie la fin\n",
    "    nom = \".\"\n",
    "    while nom[-1] != \".\" or len(nom) == 1:\n",
    "        next_char = int_to_char[torch.multinomial(P, num_samples=1, replacement=True, generator=g).item()]\n",
    "        nom = nom + next_char\n",
    "    print(nom[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9820)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcul du coût\n",
    "# cette fois, on parcours toutes les données\n",
    "# rappel de la formule : moyenne(log p_modele(lettre suivante | contexte))\n",
    "# la moyenne se fait sur l'entièreté d'un nom de commune, et sur l'ensemble des noms de communes\n",
    "\n",
    "nll = 0\n",
    "for i in range(X.shape[0]):\n",
    "    nll += torch.log(P[X[i, 0]]) # log p_modele(lettre) (contexte vide ici)\n",
    "-nll/X.shape[0] # moyenne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création du dataset\n",
    "\n",
    "# matrice des données, qui sera de taille (M, 2) pour le bigram\n",
    "# on y place les lettres deux par deux \n",
    "# par exemple, à partir de paris, on construirait les exemples \".p\", \"pa\", \"ar\", \"ri\", \"is\", \"s.\"\n",
    "\n",
    "X = []\n",
    "\n",
    "for ville in villes:\n",
    "    for ch1, ch2 in zip(ville, ville[1:]):\n",
    "        X.append([char_to_int[ch1], char_to_int[ch2]])\n",
    "\n",
    "X = torch.asarray(X) # (M, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modèle bigram\n",
    "P = torch.zeros((len(vocabulaire), len(vocabulaire))) # liste de probabilités d'apparition de chaque couple\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    P[X[i, 0], X[i, 1]] += 1 # on augmente le compteur de chaque couple rencontré\n",
    "\n",
    "P = P / P.sum(dim=1, keepdim=True) # on divise pour obtenir des probabilitiés\n",
    "# la dimension 0 correspond à la première lettre de chaque couple (le contexte)\n",
    "# la dimension 1 à la seconde lettre (la lettre prédite)\n",
    "\n",
    "# par exemple, P[char_to_int['a']] correspond à 45 nombres, la distribution de probabilités sur les lettres qui suivent le a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layst\n",
      "stl\n",
      "pin-s-d-sus\n",
      "chisspen\n",
      "moue c-gu-main-peu\n",
      "llergnch\n",
      "cheusollet\n",
      "lle\n",
      "bllaint-lenévir-sesas-penaiemey\n",
      "norgitagesa\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(42+4)\n",
    "\n",
    "for _ in range(10):\n",
    "    nom = \".\"\n",
    "    while nom[-1] != \".\" or len(nom) == 1:\n",
    "        last_char = nom[-1]\n",
    "        next_char = int_to_char[torch.multinomial(P[char_to_int[last_char]], num_samples=1, replacement=True, generator=g).item()]\n",
    "        nom = nom + next_char\n",
    "    print(nom[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3906)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcul du coût\n",
    "# rappel de la formule : moyenne(log p_modele(lettre suivante | contexte))\n",
    "# la moyenne se fait sur l'entièreté d'un nom de commune, et sur l'ensemble des noms de communes\n",
    "\n",
    "nll = 0\n",
    "for i in range(X.shape[0]):\n",
    "    nll += torch.log(P[X[i, 0], X[i, 1]]) # log p_modele(lettre | contexte) avec contexte = X[i, 0], lettre = X[i, 1]\n",
    "-nll/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nombre de paramètres : 1936'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Nombre de paramètres : {len(vocabulaire)*len(vocabulaire)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on rajoute le token . au début et en fin\n",
    "for ville, i in zip(villes, range(len(villes))):\n",
    "    villes[i] = '.' + ville + \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création du dataset\n",
    "\n",
    "X = [] # taille (M, 3) pour le trigram\n",
    "\n",
    "# pour paris, on construit \"..p\", \".pa\", \"par\", \"ari\", \"ris\", \"is.\", \"s..\"\n",
    "# d'où la nécessite de rajouter un . au début et à la fin\n",
    "\n",
    "for ville in villes:\n",
    "    for ch1, ch2, ch3 in zip(ville, ville[1:], ville[2:]):\n",
    "        X.append([char_to_int[ch1], char_to_int[ch2], char_to_int[ch3]])\n",
    "\n",
    "X = torch.asarray(X) # (M, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modèle trigram\n",
    "P = torch.zeros((len(vocabulaire), len(vocabulaire), len(vocabulaire))) # une proba pour chaque trio de lettre\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    P[X[i, 0], X[i, 1], X[i, 2]] += 1\n",
    "\n",
    "P = P / P.sum(dim=2, keepdim=True) # la dernière dimension correspond à la prochain lettre, les 2 premières aux lettres de contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "igorville\n",
      "sérômes-ne\n",
      "pes\n",
      "mille\n",
      "carren-d'as\n",
      "quintotse\n",
      "print-méneux\n",
      "lournac\n",
      "la-venoisille pelle\n",
      "gace\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(4354)\n",
    "\n",
    "for _ in range(10):\n",
    "    nom = \"..\"\n",
    "    while nom[-1] != \".\" or len(nom) == 2:\n",
    "        char_moins_1 = nom[-1]\n",
    "        char_moins_2 = nom[-2]\n",
    "\n",
    "        next_char = int_to_char[torch.multinomial(P[char_to_int[char_moins_2], char_to_int[char_moins_1]], num_samples=1, replacement=True, generator=g).item()]\n",
    "        nom = nom + next_char\n",
    "\n",
    "    print(nom[2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8118)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss\n",
    "nll = 0\n",
    "for i in range(X.shape[0]):\n",
    "    nll += torch.log(P[X[i, 0], X[i, 1], X[i, 2]]) # log p_modele(lettre | contexte)\n",
    "-nll/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nombre de paramètres : 85184'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Nombre de paramètres : {len(vocabulaire)**3}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
