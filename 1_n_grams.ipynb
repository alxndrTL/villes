{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement des données\n",
    "\n",
    "fichier = open('villes.txt')\n",
    "donnees = fichier.read()\n",
    "villes = donnees.replace('\\n', ',').split(',')\n",
    "\n",
    "# préparation des données\n",
    "\n",
    "# on rajoute le token . au début et en fin\n",
    "for ville, i in zip(villes, range(len(villes))):\n",
    "    villes[i] = '.' + ville + '.'\n",
    "\n",
    "# création du vocabulaire\n",
    "vocabulaire = []\n",
    "\n",
    "for ville in villes:\n",
    "    for c in ville:\n",
    "        if c not in vocabulaire:\n",
    "            vocabulaire.append(c)\n",
    "\n",
    "vocabulaire = sorted(vocabulaire)\n",
    "vocabulaire[0] = '.' # 0 est \" \" et 3 est \".\" -> on échange\n",
    "vocabulaire[3] = ' '\n",
    "\n",
    "# pour convertir char <-> int\n",
    "char_to_int = {}\n",
    "int_to_char = {}\n",
    "\n",
    "for (c, i) in zip(vocabulaire, range(len(vocabulaire))):\n",
    "    char_to_int[c] = i\n",
    "    int_to_char[i] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"liô.œëz'üq-fx.x\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(random.choice(vocabulaire) for _ in range(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7842)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss\n",
    "-torch.log(torch.tensor(1/len(vocabulaire)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création du dataset\n",
    "\n",
    "X = []\n",
    "\n",
    "for ville in villes:\n",
    "    for char in ville:\n",
    "        X.append([char_to_int[char]])\n",
    "\n",
    "X = torch.asarray(X) # (M, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modèle uni-gram\n",
    "P = torch.zeros((len(vocabulaire)))\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    P[X[i]] += 1\n",
    "\n",
    "P = P / P.sum(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-assdaie\n",
      "lulicutgnnc\n",
      "htronitha\n",
      "\n",
      "i\n",
      "n\n",
      "eouurs\n",
      "as-\n",
      "aeeeuzmèveoavnisfcnanne-msnttaèsere-ecla\n",
      "rue\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(40)\n",
    "\n",
    "for _ in range(10):\n",
    "    nom = \".\"\n",
    "    while nom[-1] != \".\" or len(nom) ==1:\n",
    "        next_char = int_to_char[torch.multinomial(P, num_samples=1, replacement=True, generator=g).item()]\n",
    "        nom = nom + next_char\n",
    "    print(nom[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9820)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss\n",
    "nll = 0\n",
    "for i in range(X.shape[0]):\n",
    "    nll += torch.log(P[X[i, 0]])\n",
    "-nll/X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création du dataset\n",
    "\n",
    "X = []\n",
    "\n",
    "for ville in villes:\n",
    "    for ch1, ch2 in zip(ville, ville[1:]):\n",
    "        X.append([char_to_int[ch1], char_to_int[ch2]])\n",
    "\n",
    "X = torch.asarray(X) # (M, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modèle bigram\n",
    "P = torch.zeros((len(vocabulaire), len(vocabulaire)))\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    P[X[i, 0], X[i, 1]] += 1\n",
    "\n",
    "P = P / P.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vallaleis\n",
      "che\n",
      "lil-hyes\n",
      "be-san\n",
      "borstay\n",
      "et-lboinaimmoufenne-haix-mile\n",
      "s-veulssat\n",
      "mom\n",
      "lan\n",
      "vizailonsenoroue\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(42)\n",
    "\n",
    "for _ in range(10):\n",
    "    nom = \".\"\n",
    "    while nom[-1] != \".\" or len(nom) == 1:\n",
    "        last_char = nom[-1]\n",
    "        next_char = int_to_char[torch.multinomial(P[char_to_int[last_char]], num_samples=1, replacement=True, generator=g).item()]\n",
    "        nom = nom + next_char\n",
    "    print(nom[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3906)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss\n",
    "nll = 0\n",
    "for i in range(X.shape[0]):\n",
    "    nll += torch.log(P[X[i, 0], X[i, 1]])\n",
    "-nll/X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on rajoute le token . au début et en fin\n",
    "for ville, i in zip(villes, range(len(villes))):\n",
    "    villes[i] = '.' + ville + \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création du dataset\n",
    "\n",
    "X = []\n",
    "\n",
    "for ville in villes:\n",
    "    for ch1, ch2, ch3 in zip(ville, ville[1:], ville[2:]):\n",
    "        X.append([char_to_int[ch1], char_to_int[ch2], char_to_int[ch3]])\n",
    "\n",
    "X = torch.asarray(X) # (M, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modèle trigram\n",
    "P = torch.zeros((len(vocabulaire), len(vocabulaire), len(vocabulaire)))\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    P[X[i, 0], X[i, 1], X[i, 2]] += 1\n",
    "\n",
    "P = P / P.sum(dim=2, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sains\n",
      "tot-haint-de-an-surds\n",
      "gillersville\n",
      "porberreville\n",
      "sainet\n",
      "saint-mellesnince\n",
      "ville-doucy\n",
      "saint-de-bois\n",
      "brémont\n",
      "sénaint-surquils\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(43)\n",
    "\n",
    "for _ in range(10):\n",
    "    nom = \"..\"\n",
    "    while nom[-1] != \".\" or len(nom) == 2:\n",
    "        char_moins_1 = nom[-1]\n",
    "        char_moins_2 = nom[-2]\n",
    "\n",
    "        next_char = int_to_char[torch.multinomial(P[char_to_int[char_moins_2], char_to_int[char_moins_1]], num_samples=1, replacement=True, generator=g).item()]\n",
    "        nom = nom + next_char\n",
    "\n",
    "    print(nom[2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8118)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss\n",
    "nll = 0\n",
    "for i in range(X.shape[0]):\n",
    "    nll += torch.log(P[X[i, 0], X[i, 1], X[i, 2]])\n",
    "-nll/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
