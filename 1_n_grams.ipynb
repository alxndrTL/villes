{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement des données\n",
    "\n",
    "fichier = open('villes.txt')\n",
    "donnees = fichier.read()\n",
    "villes = donnees.replace('\\n', ',').split(',')\n",
    "\n",
    "# préparation des données\n",
    "\n",
    "# on rajoute le token . au début et en fin\n",
    "for ville, i in zip(villes, range(len(villes))):\n",
    "    villes[i] = '.' + ville + '.'\n",
    "\n",
    "# création du vocabulaire\n",
    "vocabulaire = []\n",
    "\n",
    "for ville in villes:\n",
    "    for c in ville:\n",
    "        if c not in vocabulaire:\n",
    "            vocabulaire.append(c)\n",
    "\n",
    "vocabulaire = sorted(vocabulaire)\n",
    "vocabulaire[0] = '.' # 0 est \" \" et 3 est \".\" -> on échange\n",
    "vocabulaire[3] = ' '\n",
    "\n",
    "# pour convertir char <-> int\n",
    "char_to_int = {}\n",
    "int_to_char = {}\n",
    "\n",
    "for (c, i) in zip(vocabulaire, range(len(vocabulaire))):\n",
    "    char_to_int[c] = i\n",
    "    int_to_char[i] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random (0-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ednês-ü.ÿçenx-rammêfn.vzôeeœto'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(random.choice(vocabulaire) for _ in range(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7842)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss\n",
    "-torch.log(torch.tensor(1/len(vocabulaire)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création du dataset\n",
    "\n",
    "X = []\n",
    "\n",
    "for ville in villes:\n",
    "    for char in ville:\n",
    "        X.append([char_to_int[char]])\n",
    "\n",
    "X = torch.asarray(X) # (M, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modèle uni-gram\n",
    "P = torch.zeros((len(vocabulaire)))\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    P[X[i]] += 1\n",
    "\n",
    "P = P / P.sum(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a-cqsu\n",
      "n\n",
      "o\n",
      "sayoemnraro\n",
      "\n",
      "ianèriaesom\n",
      "aom--ei\n",
      "l\n",
      "oitabu\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(40+5)\n",
    "\n",
    "for _ in range(10):\n",
    "    nom = \".\"\n",
    "    while nom[-1] != \".\" or len(nom) ==1:\n",
    "        next_char = int_to_char[torch.multinomial(P, num_samples=1, replacement=True, generator=g).item()]\n",
    "        nom = nom + next_char\n",
    "    print(nom[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9820)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss\n",
    "nll = 0\n",
    "for i in range(X.shape[0]):\n",
    "    nll += torch.log(P[X[i, 0]])\n",
    "-nll/X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création du dataset\n",
    "\n",
    "X = []\n",
    "\n",
    "for ville in villes:\n",
    "    for ch1, ch2 in zip(ville, ville[1:]):\n",
    "        X.append([char_to_int[ch1], char_to_int[ch2]])\n",
    "\n",
    "X = torch.asarray(X) # (M, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modèle bigram\n",
    "P = torch.zeros((len(vocabulaire), len(vocabulaire)))\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    P[X[i, 0], X[i, 1]] += 1\n",
    "\n",
    "P = P / P.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7436)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*P[char_to_int['z'], char_to_int['z']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layst\n",
      "stl\n",
      "pin-s-d-sus\n",
      "chisspen\n",
      "moue c-gu-main-peu\n",
      "llergnch\n",
      "cheusollet\n",
      "lle\n",
      "bllaint-lenévir-sesas-penaiemey\n",
      "norgitagesa\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(42+4)\n",
    "\n",
    "for _ in range(10):\n",
    "    nom = \".\"\n",
    "    while nom[-1] != \".\" or len(nom) == 1:\n",
    "        last_char = nom[-1]\n",
    "        next_char = int_to_char[torch.multinomial(P[char_to_int[last_char]], num_samples=1, replacement=True, generator=g).item()]\n",
    "        nom = nom + next_char\n",
    "    print(nom[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3906)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss\n",
    "nll = 0\n",
    "for i in range(X.shape[0]):\n",
    "    nll += torch.log(P[X[i, 0], X[i, 1]])\n",
    "-nll/X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on rajoute le token . au début et en fin\n",
    "for ville, i in zip(villes, range(len(villes))):\n",
    "    villes[i] = '.' + ville + \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création du dataset\n",
    "\n",
    "X = []\n",
    "\n",
    "for ville in villes:\n",
    "    for ch1, ch2, ch3 in zip(ville, ville[1:], ville[2:]):\n",
    "        X.append([char_to_int[ch1], char_to_int[ch2], char_to_int[ch3]])\n",
    "\n",
    "X = torch.asarray(X) # (M, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modèle trigram\n",
    "P = torch.zeros((len(vocabulaire), len(vocabulaire), len(vocabulaire)))\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    P[X[i, 0], X[i, 1], X[i, 2]] += 1\n",
    "\n",
    "P = P / P.sum(dim=2, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*P[char_to_int['z'], char_to_int['z'], char_to_int['z']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "igorville\n",
      "sérômes-ne\n",
      "pes\n",
      "mille\n",
      "carren-d'as\n",
      "quintotse\n",
      "print-méneux\n",
      "lournac\n",
      "la-venoisille pelle\n",
      "gace\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(4354)\n",
    "\n",
    "for _ in range(10):\n",
    "    nom = \"..\"\n",
    "    while nom[-1] != \".\" or len(nom) == 2:\n",
    "        char_moins_1 = nom[-1]\n",
    "        char_moins_2 = nom[-2]\n",
    "\n",
    "        next_char = int_to_char[torch.multinomial(P[char_to_int[char_moins_2], char_to_int[char_moins_1]], num_samples=1, replacement=True, generator=g).item()]\n",
    "        nom = nom + next_char\n",
    "\n",
    "    print(nom[2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8118)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss\n",
    "nll = 0\n",
    "for i in range(X.shape[0]):\n",
    "    nll += torch.log(P[X[i, 0], X[i, 1], X[i, 2]])\n",
    "-nll/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
